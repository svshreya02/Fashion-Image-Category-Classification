{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm  \n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((60, 80)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels_df[1] = self.label_encoder.fit_transform(self.labels_df[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = torch.tensor(self.labels_df.iloc[idx, 1], dtype=torch.long)  # Convert label to tensor\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create custom dataset\n",
    "dataset = CustomDataset(csv_file='/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/labels.txt', root_dir='/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/images', transform=transform)\n",
    "\n",
    "# Load the trained model for prediction\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.label_encoder.classes_))\n",
    "model.load_state_dict(torch.load( '/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/models/torch.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Define function to predict category of a query image\n",
    "def predict_category(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_label = dataset.label_encoder.inverse_transform([predicted.item()])  # Convert to list\n",
    "    return predicted_label[0]\n",
    "\n",
    "def extract_colors(image_path, num_colors=5):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise and improve contour detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Binary thresholding\n",
    "    _, binary_thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours from the binary threshold image\n",
    "    contours, hierarchy = cv2.findContours(binary_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask for the largest contour\n",
    "    mask = np.zeros_like(gray)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Fill the largest contour to create a solid shape\n",
    "        cv2.drawContours(mask, [largest_contour], -1, color=255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Extract the masked area for color analysis\n",
    "    # Get indices where mask is not zero (i.e., inside the contour)\n",
    "    idx = np.where(mask != 0)\n",
    "    pixels = image[idx[0], idx[1], :]\n",
    "\n",
    "    # Apply K-means clustering to find dominant colors\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "    colors = kmeans.cluster_centers_\n",
    "\n",
    "    # Get the labels assigned to each pixel\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Count the occurrences of each label\n",
    "    counts = np.bincount(labels)\n",
    "\n",
    "    return colors.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#COVERT RGB TO HEX\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "\n",
    "def display_colors_sorted(colors, counts):\n",
    "    # Sort colors and counts based on counts\n",
    "    sorted_indices = np.argsort(counts)[::-1]\n",
    "    sorted_colors = [colors[i] for i in sorted_indices]\n",
    "    sorted_counts = [counts[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create a square image with the sorted colors\n",
    "    color_img = np.zeros((100, len(sorted_colors)*100, 3), dtype=np.uint8)\n",
    "    for i, color in enumerate(sorted_colors):\n",
    "        color_img[:, i*100:(i+1)*100] = color\n",
    "        hex_color = rgb_to_hex(color)\n",
    "  \n",
    "    \n",
    "    plt.imshow(color_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return sorted_colors  # Return the sorted colors for further use\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category for query image: Personal Care\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABRCAYAAABxPXV4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAABkElEQVR4nO3asUlEQRRA0ffX1QJMTe3CGgRzsQUbEAxsUQysQS1gFfdbgYb3B56TvuQxDJcJZlnXdQBo7LZeAOA/EV2AkOgChEQXICS6ACHRBQjt/xp+vL37TzYzh8Nhnh4e5+vza+tVNnf8/p7X55dZj67G6cl+7m/u5mx/uvUq21uWOb+8mGXnHTczc3V7vfw2c0IAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCC3rum69A8C/4aULEBJdgJDoAoREFyAkugAh0QUI/QAgrxydIs4VzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "query_image_path = \"/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/nail.jpeg\"  # Full path to the image file\n",
    "\n",
    "# Display the image without background\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(masked_image)\n",
    "plt.title(\"Image without background\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "predicted_category = predict_category(query_image_path)  # Call predict_category with the correct image path\n",
    "colors= extract_colors(query_image_path)\n",
    "print(f\"Predicted category for query image: {predicted_category}\")\n",
    "print(\"\\n\")\n",
    "sorted_colors = display_colors_sorted(colors, counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

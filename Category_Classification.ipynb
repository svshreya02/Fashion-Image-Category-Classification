{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm  \n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((60, 80)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels_df[1] = self.label_encoder.fit_transform(self.labels_df[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label = torch.tensor(self.labels_df.iloc[idx, 1], dtype=torch.long)  # Convert label to tensor\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create custom dataset\n",
    "dataset = CustomDataset(csv_file='/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/labels.txt', root_dir='/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/images', transform=transform)\n",
    "\n",
    "# Load the trained model for prediction\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.label_encoder.classes_))\n",
    "model.load_state_dict(torch.load( '/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/models/torch.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Define function to predict category of a query image\n",
    "def predict_category(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_label = dataset.label_encoder.inverse_transform([predicted.item()])  # Convert to list\n",
    "    return predicted_label[0]\n",
    "\n",
    "def extract_colors(image_path, num_colors=5):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image from BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Flatten the image to a 2D array of pixels\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    \n",
    "    # Apply K-means clustering to find dominant colors\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "    \n",
    "    # Get the dominant colors\n",
    "    colors = kmeans.cluster_centers_\n",
    "    \n",
    "    return colors.astype(int)\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "def display_colors(colors):\n",
    "    # Create a square image with the extracted colors\n",
    "    color_img = np.zeros((100, len(colors)*100, 3), dtype=np.uint8)\n",
    "    for i, color in enumerate(colors):\n",
    "        color_img[:, i*100:(i+1)*100] = color\n",
    "        # Convert RGB to hex and print\n",
    "        hex_color = rgb_to_hex(color)\n",
    "        print(f\"Color {i+1}: {hex_color}\")\n",
    "     \n",
    "    print(\"\\n\")\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(color_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category for query image: Apparel\n",
      "\n",
      "\n",
      "Color 1: #0201c3\n",
      "Color 2: #fefefd\n",
      "Color 3: #04037f\n",
      "Color 4: #898bc8\n",
      "Color 5: #0201a7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABRCAYAAABxPXV4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACCElEQVR4nO3asU0cURiF0be7QLId4DpowFW4FktOkFN35UoITAUgwcqMKwBdS7/uBJyTTjLJfHq68w7bti0AOo57vwDAZyK6AEWiC1AkugBFogtQJLoARVcfPTwdf7tPttY6n4/rz+PdOp9Pe7/K7p6eXteX21/r+fmy96vs7vr6tL7/+Lpubj78jD6F15e39fP+YV0ukrHWWn/fvh3ee+akC1AkugBFogtQJLoBKxUwRXQD7y7iAP9JdANOusAU0Q046QJTRDfgpAtMEV2AItENmBeAKaIbMC8AU0Q34KQLTBFdgCLRDZgXgCmiGzAvAFNEF6BIdAGKRBegSHQBikQ34PYCMEV0A24vAFNEF6BIdAPmBWCK6AIUiW7ApgtMEd2AeQGYIroARaILUCS6AZsuMEV0AzZdYIroAhSJbsC8AEwRXYAi0Q3YdIEpohswLwBTRDfgpAtMEV2AItENmBeAKaILUCS6AZsuMEV0A+YFYIroBpx0gSmiC1AkugBFohuw6QJTRBegSHQDfqQBU0QXoEh0AzZdYIroBswLwBTRBSgS3YB5AZgiugHzAjBFdAGKRDdgXgCmiC5AkegGbLrAFNEFKBJdgCLRBSgS3YDbC8AU0QUoEt2A2wvAFNEFKBJdgCLRDfiRBkw5bJvFEqDFSRegSHQBikQXoEh0AYpEF6BIdAGK/gH1TS6dmZZsGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "query_image_path = \"/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/blue.jpeg\"  # Full path to the image file\n",
    "predicted_category = predict_category(query_image_path)  # Call predict_category with the correct image path\n",
    "colors = extract_colors(query_image_path)\n",
    "print(f\"Predicted category for query image: {predicted_category}\")\n",
    "print(\"\\n\")\n",
    "display_colors(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colour Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_shades_df = pd.read_csv('/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/colours_rgb_shades_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_hex_color(extracted_hex_colors, color_df):\n",
    "    closest_colors = []\n",
    "    for hex_color in extracted_hex_colors:\n",
    "        hex_color = hex_color.lstrip('#')  # Ensure we're working with the HEX part only\n",
    "\n",
    "        # Calculate the distance to each color in the dataframe\n",
    "        distances = color_df['RGB Hex'].apply(\n",
    "            lambda x: sum((int(x[i:i+2], 16) - int(hex_color[i:i+2], 16)) ** 2 for i in (0, 2, 4))\n",
    "            if len(x) == 6 else float('inf')\n",
    "        )\n",
    "\n",
    "        # Get the index of the closest color\n",
    "        closest_index = distances.idxmin()\n",
    "        closest_color = color_df.iloc[closest_index]\n",
    "        closest_colors.append((closest_color['Color Name'], closest_color['RGB Hex']))\n",
    "\n",
    "    return closest_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest color names and HEX values:\n",
      "New Midnight Blue: #00009C\n",
      "grey100, White: #FFFFFF\n",
      "Dark Turquoise: #7093DB\n",
      "blue4: #00008B\n",
      "MediumBlue: #0000CD\n",
      "\n",
      "\n",
      "Color 1: #0201a7\n",
      "Color 2: #fefefd\n",
      "Color 3: #898bc8\n",
      "Color 4: #04037f\n",
      "Color 5: #0201c3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABRCAYAAABxPXV4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACAklEQVR4nO3awW1TQRiF0bHNzi0hUUKKikQHiBaoghqoAnpw7AwVJLpIv+5Dyjlbb0ZefBrdN6e99wKg43z0AQA+EtEFKBJdgCLRBSgSXYAi0QUo+vTej5fzD+/J1lrX62X9/vO0rtd3/64P4XZ7rG/ff637/fXooxzudruvr88/18vL4+ijHG7v89r7y1rrcvRR/guP18+nt35z0wUoEl2AItEFKBLdgGEbmCK6gTcXcYB/JLoBN11giugG3HSBKaIbcNMFpoguQJHoBswLwBTRDZgXgCmiG3DTBaaILkCR6AbMC8AU0Q2YF4ApogtQJLoARaILUCS6AEWiG/B6AZgiugGvF4ApogtQJLoB8wIwRXQBikQ3YNMFpohuwLwATBFdgCLRBSgS3YBNF5giugGbLjBFdAGKRDdgXgCmiC5AkegGbLrAFNENmBeAKaIbcNMFpoguQJHoBswLwBTRBSgS3YBNF5giugHzAjBFdANuusAU0QUoEl2AItEN2HSBKaILUCS6AR/SgCmiC1AkugGbLjBFdAPmBWCK6AIUiW7AvABMEd2AeQGYIroARaIbMC8AU0QXoEh0AzZdYIroAhSJLkCR6AIUiW7A6wVgiugCFIluwOsFYIroAhSJLkCR6AZ8SAOmnPa2WAK0uOkCFIkuQJHoAhSJLkCR6AIUiS5A0V/ZgTKdDbogSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "#query_image_path = \"/home/jovyan/efs/users/Shreya_Sivakumar/TASK_1/data/glass.png\"  # Full path to the image file\n",
    "predicted_category = predict_category(query_image_path)  \n",
    "colors = extract_colors(query_image_path)\n",
    "\n",
    "# Convert extracted colors to HEX format\n",
    "extracted_hex_colors = [rgb_to_hex(color) for color in colors]\n",
    "\n",
    "# Find and display the closest colors along with their names\n",
    "closest_colors_info = find_closest_hex_color(extracted_hex_colors, rgb_shades_df)\n",
    "print(\"Closest color names and HEX values:\")\n",
    "for color_name, hex_color in closest_colors_info:\n",
    "    print(f\"{color_name}: #{hex_color}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# Optionally, display the extracted colors\n",
    "display_colors(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
